{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de Imagenes\n",
    "img = cv.imread('C:/Users/c679529/Documents/GitHub/aprMaqI_CEIA/vision_computadora_I/Material_TPs/TP1/coord_cromaticas/CoordCrom_1.jpg')\n",
    "img2 = cv.imread('C:/Users/c679529/Documents/GitHub/aprMaqI_CEIA/vision_computadora_I/Material_TPs/TP1/coord_cromaticas/CoordCrom_2.png')\n",
    "img3 = cv.imread('C:/Users/c679529/Documents/GitHub/aprMaqI_CEIA/vision_computadora_I/Material_TPs/TP1/coord_cromaticas/CoordCrom_3.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c679529\\AppData\\Local\\Temp\\ipykernel_22268\\2462383609.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  chromatic_coordinates = np.stack([r / (r + g + b), g / (r + g + b), b / (r + g + b)], axis=-1)\n"
     ]
    }
   ],
   "source": [
    "#Armo una funcion para convertir matematicamente una imagen en coordenadas cromaticas\n",
    "\n",
    "def convert_to_chromatic_coordinates(rgb_image):\n",
    "    # Normalizar los valores de píxeles al rango [0, 1]\n",
    "    normalized_image = rgb_image / 255.0\n",
    "    \n",
    "    # Calcular las coordenadas cromáticas\n",
    "    r, g, b = normalized_image[:,:,0], normalized_image[:,:,1], normalized_image[:,:,2]\n",
    "    \n",
    "    chromatic_coordinates = np.stack([r / (r + g + b), g / (r + g + b), b / (r + g + b)], axis=-1)\n",
    "    \n",
    "    return chromatic_coordinates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c679529\\AppData\\Local\\Temp\\ipykernel_22268\\2462383609.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  chromatic_coordinates = np.stack([r / (r + g + b), g / (r + g + b), b / (r + g + b)], axis=-1)\n"
     ]
    }
   ],
   "source": [
    "# Cargo la imagen para probar la funcion \n",
    "rgb_image =img2\n",
    "\n",
    "# Llamada a la función\n",
    "chromatic_coordinates_image = convert_to_chromatic_coordinates(rgb_image)\n",
    "\n",
    "# Visualizar la imagen original y la imagen en coordenadas cromáticas\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Original Image\n",
    "ax[0].imshow(rgb_image)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "# Chromatic Coordinates Image\n",
    "ax[1].imshow(chromatic_coordinates_image)\n",
    "ax[1].set_title('Chromatic Coordinates Image')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Armo una funcion para aplicar algoritmo de white Patch \n",
    "\n",
    "def white_patch(image):\n",
    "    # Normalizar los valores de píxeles al rango [0, 1]\n",
    "    normalized_image = image / 255.0\n",
    "    \n",
    "    # Encontrar el píxel más brillante en la imagen\n",
    "    brightest_pixel_value = np.max(normalized_image)\n",
    "    \n",
    "    # Aplicar el algoritmo White Patch\n",
    "    white_patch_image = normalized_image / brightest_pixel_value\n",
    "    \n",
    "    return white_patch_image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargo imagenes para probar algoritmo\n",
    "img_w1=cv.imread('C:/Users/c679529/Documents/GitHub/aprMaqI_CEIA/vision_computadora_I/Material_TPs/TP1/white_patch/test_blue.png')\n",
    "img_w2=cv.imread('C:/Users/c679529/Documents/GitHub/aprMaqI_CEIA/vision_computadora_I/Material_TPs/TP1/white_patch/test_green.png')\n",
    "img_w3=cv.imread('C:/Users/c679529/Documents/GitHub/aprMaqI_CEIA/vision_computadora_I/Material_TPs/TP1/white_patch/test_red.png')\n",
    "img_w4=cv.imread('C:/Users/c679529/Documents/GitHub/aprMaqI_CEIA/vision_computadora_I/Material_TPs/TP1/white_patch/wp_blue.jpg')\n",
    "img_w5=cv.imread('C:/Users/c679529/Documents/GitHub/aprMaqI_CEIA/vision_computadora_I/Material_TPs/TP1/white_patch/wp_green.png')\n",
    "img_w6=cv.imread('C:/Users/c679529/Documents/GitHub/aprMaqI_CEIA/vision_computadora_I/Material_TPs/TP1/white_patch/wp_green2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluo la funcion en cada imagen \n",
    "img_mod_w1=white_patch(img_w1)\n",
    "img_mod_w2=white_patch(img_w2)\n",
    "img_mod_w3=white_patch(img_w3)\n",
    "img_mod_w4=white_patch(img_w4)\n",
    "img_mod_w5=white_patch(img_w5)\n",
    "img_mod_w6=white_patch(img_w6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nueva figura\n",
    "fig = plt.figure()\n",
    "\n",
    "# Imagen original\n",
    "ax1=plt.subplot(221)\n",
    "ax1.imshow(img_w1, cmap='gray', vmin=0, vmax=255)\n",
    "ax1.set_title('Original')\n",
    "\n",
    "# Imagen White_patch\n",
    "\n",
    "\n",
    "ax2=plt.subplot(222)\n",
    "ax2.imshow(img_mod_w1, vmin=0, vmax=255)\n",
    "ax2.set_title('White_patch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nueva figura\n",
    "fig = plt.figure()\n",
    "\n",
    "# Imagen original\n",
    "ax1=plt.subplot(221)\n",
    "ax1.imshow(img_w2, cmap='gray', vmin=0, vmax=255)\n",
    "ax1.set_title('Original')\n",
    "\n",
    "# Imagen White_patch\n",
    "\n",
    "\n",
    "ax2=plt.subplot(222)\n",
    "ax2.imshow(img_mod_w2, vmin=0, vmax=255)\n",
    "ax2.set_title('White_patch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nueva figura\n",
    "fig = plt.figure()\n",
    "\n",
    "# Imagen original\n",
    "ax1=plt.subplot(221)\n",
    "ax1.imshow(img_w3, cmap='gray', vmin=0, vmax=255)\n",
    "ax1.set_title('Original')\n",
    "\n",
    "# Imagen White_patch\n",
    "\n",
    "\n",
    "ax2=plt.subplot(222)\n",
    "ax2.imshow(img_mod_w3, vmin=0, vmax=255)\n",
    "ax2.set_title('White_patch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nueva figura\n",
    "fig = plt.figure()\n",
    "\n",
    "# Imagen original\n",
    "ax1=plt.subplot(221)\n",
    "ax1.imshow(img_w4, cmap='gray', vmin=0, vmax=255)\n",
    "ax1.set_title('Original')\n",
    "\n",
    "# Imagen White_patch\n",
    "\n",
    "\n",
    "ax2=plt.subplot(222)\n",
    "ax2.imshow(img_mod_w4, vmin=0, vmax=255)\n",
    "ax2.set_title('White_patch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nueva figura\n",
    "fig = plt.figure()\n",
    "\n",
    "# Imagen original\n",
    "ax1=plt.subplot(221)\n",
    "ax1.imshow(img_w5, cmap='gray', vmin=0, vmax=255)\n",
    "ax1.set_title('Original')\n",
    "\n",
    "# Imagen White_patch\n",
    "\n",
    "\n",
    "ax2=plt.subplot(222)\n",
    "ax2.imshow(img_mod_w5, vmin=0, vmax=255)\n",
    "ax2.set_title('White_patch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nueva figura\n",
    "fig = plt.figure()\n",
    "\n",
    "# Imagen original\n",
    "ax1=plt.subplot(221)\n",
    "ax1.imshow(img_w6, cmap='gray', vmin=0, vmax=255)\n",
    "ax1.set_title('Original')\n",
    "\n",
    "# Imagen White_patch\n",
    "\n",
    "\n",
    "ax2=plt.subplot(222)\n",
    "ax2.imshow(img_mod_w6, vmin=0, vmax=255)\n",
    "ax2.set_title('White_patch')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "El algoritmo White Patch se especializa en identificar el píxel más luminoso de una imagen y modificar los demás píxeles en función de este,\n",
    "bajo la suposición de que el píxel más brillante refleja una fuente de luz blanca. \n",
    "Su propósito principal es corregir las variaciones de color provocadas por distintas temperaturas de color de la luz en la imagen.\n",
    "\n",
    "Desventaja visto a traves de la evaluacion de las distintas imagenes: \n",
    "    \n",
    "el algoritmo White Patch puede resultar insuficiente en entornos complejos donde la iluminación\n",
    "es heterogénea o cuando hay presencia de fuentes de luz no blancas. La dependencia exclusiva en el píxel más brillante puede llevar \n",
    "a correcciones inadecuadas en escenarios donde la distribución de la luz es compleja, afectando negativamente la precisión del balance de blancos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_tp = cv.imread('C:/Users/c679529/Documents/GitHub/aprMaqI_CEIA/vision_computadora_I/Material_TPs/TP1/img1_tp.png')\n",
    "img2_tp = cv.imread('C:/Users/c679529/Documents/GitHub/aprMaqI_CEIA/vision_computadora_I/Material_TPs/TP1/img2_tp.png')\n",
    "\n",
    "# Convertir la imagen a escala de grises\n",
    "img1_tp = cv2.cvtColor(img1_tp, cv2.COLOR_BGR2GRAY)\n",
    "img2_tp = cv2.cvtColor(img2_tp, cv2.COLOR_BGR2GRAY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico las imagenes \n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax1=plt.subplot(221)\n",
    "ax1.imshow(img1_tp ,cmap='gray', vmin=0, vmax=255)\n",
    "ax2=plt.subplot(222)\n",
    "ax2.imshow(img2_tp,cmap='gray', vmin=0, vmax=255)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voy a graficar la primera imagen y su histograma \n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "\n",
    "axes[0].imshow(img1_tp, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0].set_title('Imagen1')\n",
    "\n",
    "\n",
    "hist1, bins1 = np.histogram(img1_tp.ravel(), 256, [0, 256])\n",
    "axes[1].plot(hist1, color='black')\n",
    "axes[1].set_title('Histogram1')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico la segunda imagen y su respectivo histograma \n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "axes[0].imshow(img2_tp, cmap='gray', vmin=0, vmax=255)\n",
    "axes[0].set_title('Imagen2')\n",
    "\n",
    "\n",
    "hist1, bins1 = np.histogram(img2_tp.ravel(), 256, [0, 256])\n",
    "axes[1].plot(hist1, color='black')\n",
    "axes[1].set_title('Histogram2')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el histograma obtenido en la primera imagen es identico a la segunda imagen.\n",
    "Los histogramas proporcionan una representación estadística de la distribución de intensidades de píxeles en una imagen y pueden capturar ciertas características visuales importantes.\n",
    "por ese motivo podrian ser utilizados como features en modelos de aprendizaje supervisado.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Leo la imagen de segmentacion\n",
    "img_seg = cv.imread('C:/Users/c679529/Documents/GitHub/aprMaqI_CEIA/vision_computadora_I/Material_TPs/TP1/segmentacion.png')\n",
    "img_seg.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separo los canales de color (BGR) de la imagen\n",
    "blue_channel = img_seg[:, :, 0]\n",
    "green_channel = img_seg[:, :, 1]\n",
    "red_channel = img_seg[:, :, 2]\n",
    "\n",
    "# Calcular los histogramas de cada canal\n",
    "hist_blue = cv2.calcHist([blue_channel], [0], None, [256], [0, 256])\n",
    "hist_green = cv2.calcHist([green_channel], [0], None, [256], [0, 256])\n",
    "hist_red = cv2.calcHist([red_channel], [0], None, [256], [0, 256])\n",
    "\n",
    "# Creo una figura para mostrar los histogramas\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Mostrar el histograma del canal azul en el primer subplot\n",
    "plt.subplot(131)\n",
    "plt.plot(hist_blue, color='blue')\n",
    "plt.title('Histograma Azul')\n",
    "plt.xlim([0, 256])\n",
    "\n",
    "# Mostrar el histograma del canal verde en el segundo subplot\n",
    "plt.subplot(132)\n",
    "plt.plot(hist_green, color='green')\n",
    "plt.title('Histograma Verde')\n",
    "plt.xlim([0, 256])\n",
    "\n",
    "# Mostrar el histograma del canal rojo en el tercer subplot\n",
    "plt.subplot(133)\n",
    "plt.plot(hist_red, color='red')\n",
    "plt.title('Histograma Rojo')\n",
    "plt.xlim([0, 256])\n",
    "\n",
    "# Mostrar la figura con los histogramas\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa de esto que en el canal Blue hay una frecuencia marcada en el rango aprox 180-230\n",
    "el canal verde se aproxima a una campana de gauss con mediana en 130 aprox\n",
    "mientras que el canal rojo , se asemeja a una distribucion uniforme donde todos los pixeles tienen frecuencia similar. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecer umbrales segun la lectura de los histogramas\n",
    "threshold_blue = (180, 230)\n",
    "threshold_green = (124, 150)\n",
    "threshold_red = (160,250)\n",
    "\n",
    "# Creo máscaras binarias x canal\n",
    "mask_blue = cv2.inRange(img[:, :, 0], *threshold_blue)\n",
    "mask_green = cv2.inRange(img[:, :, 1], *threshold_green)\n",
    "mask_red = cv2.inRange(img[:, :, 2], *threshold_red)\n",
    "\n",
    "# Mostrar las máscaras\n",
    "plt.subplot(131), plt.imshow(mask_blue, cmap='gray'), plt.title('Máscara Azul')\n",
    "plt.subplot(132), plt.imshow(mask_green, cmap='gray'), plt.title('Máscara Verde')\n",
    "plt.subplot(133), plt.imshow(mask_red, cmap='gray'), plt.title('Máscara Roja')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar máscaras a la imagen original\n",
    "segmented_blue = cv2.bitwise_and(img, img, mask=mask_blue)\n",
    "segmented_green = cv2.bitwise_and(img, img, mask=mask_green)\n",
    "segmented_red = cv2.bitwise_and(img, img, mask=mask_red)\n",
    "\n",
    "# Mostrar las imágenes segmentadas\n",
    "plt.subplot(131), plt.imshow(cv2.cvtColor(segmented_blue, cv2.COLOR_BGR2RGB)), plt.title('Segmentado Azul')\n",
    "plt.subplot(132), plt.imshow(cv2.cvtColor(segmented_green, cv2.COLOR_BGR2RGB)), plt.title('Segmentado Verde')\n",
    "plt.subplot(133), plt.imshow(cv2.cvtColor(segmented_red, cv2.COLOR_BGR2RGB)), plt.title('Segmentado Rojo')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
